{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOAXpTTHewJA",
        "outputId": "43710777-9ebe-45bd-b88a-e8142d7f2182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n",
            "\n",
            "/usr/local/cuda-11:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n",
            "\n",
            "/usr/local/cuda-11.2:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/cuda*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKAiR7zbfAWG",
        "outputId": "5e1816bf-dd24-45d2-c421-e00683aab839"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 16 15:10:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ../../bin/x86_64/linux/release/simpleOccupancy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVgwxKVtsF-",
        "outputId": "2fc617a2-95f1-46a3-ceda-1b5387145b2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==ERROR== '../../bin/x86_64/linux/release/simpleOccupancy' does not exist or is not an executable. Please make sure to specify the absolute path to '../../bin/x86_64/linux/release/simpleOccupancy' if the executable is not in the local directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <sys/time.h>\n",
        " \n",
        "// CUDA kernel. Each thread takes care of one element of c\n",
        "__global__ void vecAdd(double *a, double *b, double *c, int n)\n",
        "{\n",
        "    // Get our global thread ID\n",
        "    int id = blockIdx.x*blockDim.x+threadIdx.x;\n",
        " \n",
        "    // Make sure we do not go out of bounds\n",
        "    if (id < n)\n",
        "        c[id] = a[id] + b[id];\n",
        "}\n",
        "\n",
        "double cpuSecond() {\n",
        "   struct timeval tp;\n",
        "   gettimeofday(&tp,NULL);\n",
        "   return ((double)tp.tv_sec + (double)tp.tv_usec*1.e-6);\n",
        "}\n",
        " \n",
        "int main( int argc, char* argv[] )\n",
        "{\n",
        "    // Size of vectors\n",
        "    int n = 1024;\n",
        " \n",
        "    // Host input vectors\n",
        "    double *h_a;\n",
        "    double *h_b;\n",
        "    //Host output vector\n",
        "    double *h_c;\n",
        " \n",
        "    // Device input vectors\n",
        "    double *d_a;\n",
        "    double *d_b;\n",
        "    //Device output vector\n",
        "    double *d_c;\n",
        " \n",
        "    // Size, in bytes, of each vector\n",
        "    size_t bytes = n*sizeof(double);\n",
        " \n",
        "    // Allocate memory for each vector on host\n",
        "    h_a = (double*)malloc(bytes);\n",
        "    h_b = (double*)malloc(bytes);\n",
        "    h_c = (double*)malloc(bytes);\n",
        " \n",
        "    // Allocate memory for each vector on GPU\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        " \n",
        "    int i;\n",
        "    // Initialize vectors on host\n",
        "    for( i = 0; i < n; i++ ) {\n",
        "        h_a[i] = sin(i)*sin(i);\n",
        "        h_b[i] = cos(i)*cos(i);\n",
        "    }\n",
        " \n",
        "    // Copy host vectors to device\n",
        "    //TIME THIS\n",
        "    double hTdTime = cpuSecond();\n",
        "    cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaDeviceSynchronize();\n",
        "    double hTdTimeElapsed = cpuSecond() - hTdTime;\n",
        " \n",
        "    int blockSize, gridSize;\n",
        " \n",
        "    // Number of threads in each thread block\n",
        "    blockSize = 1024;\n",
        " \n",
        "    // Number of thread blocks in grid\n",
        "    gridSize = (int)ceil((float)n/blockSize);\n",
        " \n",
        "    // Execute the kernel\n",
        "    //TIME THIS\n",
        "    double kernelTime = cpuSecond();\n",
        "    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "    double kernelTimeElapsed = cpuSecond() - kernelTime;\n",
        "\n",
        "    // Copy array back to host\n",
        "    //TIME THIS\n",
        "    double dThTime = cpuSecond();\n",
        "    cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n",
        "    cudaDeviceSynchronize();\n",
        "    double dThTimeElapsed = cpuSecond() - dThTime;\n",
        " \n",
        "    // Sum up vector c and print result divided by n, this should equal 1 within error\n",
        "    double sum = 0;\n",
        "    for(i=0; i<n; i++)\n",
        "        sum += h_c[i];\n",
        "    printf(\"final result: %f\\n\", sum/n);\n",
        " \n",
        "    // Release device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        " \n",
        "    // Release host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "\n",
        "    printf(\"Host to Device: %f\\n\", hTdTimeElapsed);\n",
        "    printf(\"Kernel: %f\\n\", kernelTimeElapsed);\n",
        "    printf(\"Device to Host: %f\\n\", dThTimeElapsed);\n",
        " \n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb9t-xfsfTAn",
        "outputId": "6300a39f-d1c5-4007-cf4e-3b5b29552785"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd"
      ],
      "metadata": {
        "id": "IL9hXoTwXT7x"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EPsYf9ZXvzH",
        "outputId": "30286bce-b502-49dc-f201-81ccdfb1aeae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final result: 1.000000\n",
            "Host to Device: 0.003475\n",
            "Kernel: 0.000113\n",
            "Device to Host: 0.005172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli vectorAdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpOlY7SFajoR",
        "outputId": "0202b30c-31db-4303-b899-43c4e7576117"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 178 (/content/vectorAdd)\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "final result: 1.000000\n",
            "==PROF== Disconnected from process 178\n",
            "[178] vectorAdd@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2022-Dec-15 17:42:27, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.13\n",
            "    SM Frequency                                                             cycle/usecond                         600.21\n",
            "    Elapsed Cycles                                                                   cycle                          8,434\n",
            "    Memory [%]                                                                           %                          50.56\n",
            "    SOL DRAM                                                                             %                          50.56\n",
            "    Duration                                                                       usecond                          14.05\n",
            "    SOL L1/TEX Cache                                                                     %                          27.12\n",
            "    SOL L2 Cache                                                                         %                          25.18\n",
            "    SM Active Cycles                                                                 cycle                       6,041.20\n",
            "    SM [%]                                                                               %                          19.43\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                      1,024\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         128\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        131,072\n",
            "    Waves Per SM                                                                                                     3.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n",
            "          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n",
            "          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 8 thread blocks.    \n",
            "          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n",
            "          up to 25.0% of the total kernel runtime with a lower occupancy of 22.1%. Try launching a grid with no         \n",
            "          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n",
            "          a grid.                                                                                                       \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                              4\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              1\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          77.87\n",
            "    Achieved Active Warps Per SM                                                      warp                          24.92\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphing\n",
        "\n",
        "#storing the data\n",
        "#Size = 131070:\n",
        "  # Host to Device: 0.000641\n",
        "  # Kernel: 0.000043\n",
        "  # Device to Host: 0.000798\n",
        "\n",
        "#Size = 200000:\n",
        "  # Host to Device: 0.000768\n",
        "  # Kernel: 0.000064\n",
        "  # Device to Host: 0.001162\n",
        "\n",
        "#Size = 50000:\n",
        "  # Host to Device: 0.000272\n",
        "  # Kernel: 0.000028\n",
        "  # Device to Host: 0.000342\n",
        "\n",
        "#Size = 1024:\n",
        "  # Host to Device: 0.000034\n",
        "  # Kernel: 0.000049\n",
        "  # Device to Host: 0.000023\n",
        "\n",
        "#Size = 500000:\n",
        "  # Host to Device: 0.001810\n",
        "  # Kernel: 0.000066\n",
        "  # Device to Host: 0.002822\n",
        "\n",
        "#Size = 1000000:\n",
        "  # Host to Device: 0.003475\n",
        "  # Kernel: 0.000113\n",
        "  # Device to Host: 0.005172\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for the bar chart\n",
        "x = ['131070', '200000', '50000', '1024', '500000', '1000000']\n",
        "y1 = [0.000641, 0.000768, 0.000272, 0.000034, 0.001810, 0.003475]\n",
        "y2 = [0.000043, 0.000064, 0.000028, 0.000049, 0.000066, 0.000113]\n",
        "y3 = [0.000798, 0.001162, 0.000342, 0.000023, 0.002822, 0.005172]\n",
        "\n",
        "# Create the figure and the axis\n",
        "\n",
        "\n",
        "# Add the data to the plot\n",
        "plt.bar(x, y1, label=\"Host to Device\")\n",
        "plt.bar(x, y2, label=\"kernel\")\n",
        "plt.bar(x, y3, label=\"Device to Host\")\n",
        "\n",
        "# Add labels and title\n",
        "# plt.set_xlabel(\"Vector size\")\n",
        "# plt.set_ylabel(\"Time taken\")\n",
        "# plt.set_title(\"Time taken based on Vector size\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "SpfkEmNIh_s4",
        "outputId": "cb23b463-28aa-4d23-f347-67b863ce18ff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}