{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdL0L3M0rdqZ",
        "outputId": "5dcf5f6f-2d83-480d-ee0a-96ff87a868dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n",
            "\n",
            "/usr/local/cuda-11:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n",
            "\n",
            "/usr/local/cuda-11.2:\n",
            "bin\t\t   EULA.txt  libnvvp\t       nvvm-prev  src\n",
            "compat\t\t   extras    nsightee_plugins  README\t  targets\n",
            "compute-sanitizer  include   nvml\t       samples\t  tools\n",
            "DOCS\t\t   lib64     nvvm\t       share\t  version.json\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/cuda*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsZsuEtCrio2",
        "outputId": "7e45d65e-8876-4973-cea9-a6a3f114e358"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 15 16:45:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile heatEq.cu\n",
        "\n",
        "#include <cuda_runtime_api.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <cusparse_v2.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <thrust/device_ptr.h>\n",
        "#include <thrust/sequence.h>\n",
        "\n",
        "#define MEM_PREFETCH\n",
        "\n",
        "#define gpuCheck(stmt)                                               \\\n",
        "  do {                                                               \\\n",
        "      cudaError_t err = stmt;                                        \\\n",
        "      if (err != cudaSuccess) {                                      \\\n",
        "          printf(\"ERROR. Failed to run stmt %s\\n\", #stmt);           \\\n",
        "          break;                                                     \\\n",
        "      }                                                              \\\n",
        "  } while (0)\n",
        "\n",
        "// Macro to check the cuBLAS status\n",
        "#define cublasCheck(stmt)                                            \\\n",
        "  do {                                                               \\\n",
        "      cublasStatus_t err = stmt;                                     \\\n",
        "      if (err != CUBLAS_STATUS_SUCCESS) {                            \\\n",
        "          printf(\"ERROR. Failed to run cuBLAS stmt %s\\n\", #stmt);    \\\n",
        "          break;                                                     \\\n",
        "      }                                                              \\\n",
        "  } while (0)\n",
        "\n",
        "// Macro to check the cuSPARSE status\n",
        "#define cusparseCheck(stmt)                                          \\\n",
        "  do {                                                               \\\n",
        "      cusparseStatus_t err = stmt;                                   \\\n",
        "      if (err != CUSPARSE_STATUS_SUCCESS) {                          \\\n",
        "          printf(\"ERROR. Failed to run cuSPARSE stmt %s\\n\", #stmt);  \\\n",
        "          break;                                                     \\\n",
        "      }                                                              \\\n",
        "  } while (0)\n",
        "\n",
        "\n",
        "struct timeval t_start, t_end;\n",
        "void cputimer_start(){\n",
        "  gettimeofday(&t_start, 0);\n",
        "}\n",
        "void cputimer_stop(const char* info){\n",
        "  gettimeofday(&t_end, 0);\n",
        "  double time = (1000000.0*(t_end.tv_sec-t_start.tv_sec) + t_end.tv_usec-t_start.tv_usec);\n",
        "  printf(\"Timing - %s. \\t\\tElasped %.0f microseconds \\n\", info, time);\n",
        "}\n",
        "\n",
        "// Initialize the sparse matrix needed for the heat time step\n",
        "// NOTE: this seems to be CSR format\n",
        "void matrixInit(double* A, int* ArowPtr, int* AcolIndx, int dimX,\n",
        "    double alpha) {\n",
        "  // Stencil from the finete difference discretization of the equation\n",
        "  double stencil[] = { 1, -2, 1 };\n",
        "  // Variable holding the position to insert a new element\n",
        "  size_t ptr = 0;\n",
        "  // Insert a row of zeros at the beginning of the matrix\n",
        "  ArowPtr[1] = ptr;\n",
        "  // Fill the non zero entries of the matrix\n",
        "  for (int i = 1; i < (dimX - 1); ++i) {\n",
        "    // Insert the elements: A[i][i-1], A[i][i], A[i][i+1]\n",
        "    for (int k = 0; k < 3; ++k) {\n",
        "      // Set the value for A[i][i+k-1]\n",
        "      A[ptr] = stencil[k];\n",
        "      // Set the column index for A[i][i+k-1]\n",
        "      AcolIndx[ptr++] = i + k - 1;\n",
        "    }\n",
        "    // Set the number of newly added elements\n",
        "    ArowPtr[i + 1] = ptr;\n",
        "  }\n",
        "  // Insert a row of zeros at the end of the matrix\n",
        "  ArowPtr[dimX] = ptr;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  int device = 0;            // Device to be used\n",
        "  int dimX;                  // Dimension of the metal rod\n",
        "  int nsteps;                // Number of time steps to perform\n",
        "  double alpha = 0.4;        // Diffusion coefficient\n",
        "  double* temp;              // Array to store the final time step\n",
        "  double* A;                 // Sparse matrix A values in the CSR format\n",
        "  int* ARowPtr;              // Sparse matrix A row pointers in the CSR format\n",
        "  int* AColIndx;             // Sparse matrix A col values in the CSR format\n",
        "  int nzv;                   // Number of non zero values in the sparse matrix\n",
        "  double* tmp;               // Temporal array of dimX for computations\n",
        "  size_t bufferSize = 0;     // Buffer size needed by some routines\n",
        "  void* buffer = nullptr;    // Buffer used by some routines in the libraries\n",
        "  int concurrentAccessQ = 1;     // Check if concurrent access flag is set\n",
        "  double zero = 0;           // Zero constant\n",
        "  double one = 1;            // One constant\n",
        "  double norm;               // Variable for norm values\n",
        "  double error;              // Variable for storing the relative error\n",
        "  double tempLeft = 200.;    // Left heat source applied to the rod\n",
        "  double tempRight = 300.;   // Right heat source applied to the rod\n",
        "  cublasHandle_t cublasHandle;      // cuBLAS handle\n",
        "  cusparseHandle_t cusparseHandle;  // cuSPARSE handle\n",
        "  cusparseSpMatDescr_t Adescriptor;   // Mat descriptor needed by cuSPARSE\n",
        "  cusparseDnVecDescr_t tempDescriptor;\n",
        "  cusparseDnVecDescr_t tmpDescriptor;\n",
        "  \n",
        "  // Read the arguments from the command line\n",
        "  dimX = atoi(argv[1]);\n",
        "  nsteps = atoi(argv[2]);\n",
        "\n",
        "  // Print input arguments\n",
        "  printf(\"The X dimension of the grid is %d \\n\", dimX);\n",
        "  printf(\"The number of time steps to perform is %d \\n\", nsteps);\n",
        "\n",
        "  // Get if the cudaDevAttrConcurrentManagedAccess flag is set\n",
        "  gpuCheck(cudaDeviceGetAttribute(&concurrentAccessQ, cudaDevAttrConcurrentManagedAccess, device));\n",
        "\n",
        "  // Calculate the number of non zero values in the sparse matrix. This number\n",
        "  // is known from the structure of the sparse matrix\n",
        "  nzv = 3 * dimX - 6;\n",
        "   \n",
        "  \n",
        "  //  sizes of arrays\n",
        "  size_t temp_size = dimX * sizeof(double);\n",
        "  size_t tmp_size = temp_size;\n",
        "  size_t A_size = nzv * sizeof(double);\n",
        "  size_t  ARowPtr_size = (dimX+1) * sizeof(int);\n",
        "  size_t AColIndx_size = nzv * sizeof(int);\n",
        "\n",
        "  //@@ Insert the code to allocate the temp, tmp and the sparse matrix\n",
        "  //@@ arrays using Unified Memory\n",
        "  cputimer_start();\n",
        "  \n",
        "  gpuCheck( cudaMallocManaged(&temp, temp_size) );\n",
        "  gpuCheck( cudaMallocManaged(&tmp, tmp_size) );\n",
        "  gpuCheck( cudaMallocManaged(&A, A_size) );\n",
        "  gpuCheck( cudaMallocManaged(&ARowPtr, ARowPtr_size) );\n",
        "  gpuCheck( cudaMallocManaged(&AColIndx, AColIndx_size) );\n",
        "  \n",
        "  cputimer_stop(\"Allocating device memory\");\n",
        "\n",
        "\n",
        "  // Check if concurrentAccessQ is non zero in order to prefetch memory\n",
        "#ifdef MEM_PREFETCH\n",
        "  if (concurrentAccessQ) {\n",
        "    cputimer_start();\n",
        "    //@@ Insert code to prefetch in Unified Memory asynchronously to CPU\n",
        "    gpuCheck( cudaMemPrefetchAsync(temp, temp_size, cudaCpuDeviceId) );\n",
        "    gpuCheck( cudaMemPrefetchAsync(tmp, tmp_size, cudaCpuDeviceId) );\n",
        "    gpuCheck( cudaMemPrefetchAsync(A, A_size, cudaCpuDeviceId) );\n",
        "    gpuCheck( cudaMemPrefetchAsync(ARowPtr, ARowPtr_size, cudaCpuDeviceId) );\n",
        "    gpuCheck( cudaMemPrefetchAsync(AColIndx, AColIndx_size, cudaCpuDeviceId) );\n",
        "    cputimer_stop(\"Prefetching GPU memory to the host\");\n",
        "  }\n",
        "#endif\n",
        "\n",
        "  // Initialize the sparse matrix\n",
        "  cputimer_start();\n",
        "  matrixInit(A, ARowPtr, AColIndx, dimX, alpha);\n",
        "  cputimer_stop(\"Initializing the sparse matrix on the host\");\n",
        "\n",
        "  //Initiliaze the boundary conditions for the heat equation\n",
        "  cputimer_start();\n",
        "  memset(temp, 0, sizeof(double) * dimX);\n",
        "  temp[0] = tempLeft;\n",
        "  temp[dimX - 1] = tempRight;\n",
        "  cputimer_stop(\"Initializing memory on the host\");\n",
        "\n",
        "#ifdef MEM_PREFETCH\n",
        "  if (concurrentAccessQ) {\n",
        "    cputimer_start();\n",
        "    //@@ Insert code to prefetch in Unified Memory asynchronously to the GPU\n",
        "  cudaGetDevice(&device);\n",
        "  gpuCheck( cudaMemPrefetchAsync(temp, temp_size, device) );\n",
        "  gpuCheck( cudaMemPrefetchAsync(tmp, tmp_size, device) );\n",
        "  gpuCheck( cudaMemPrefetchAsync(A, A_size, device) );\n",
        "  gpuCheck( cudaMemPrefetchAsync(ARowPtr, ARowPtr_size, device) );\n",
        "  gpuCheck( cudaMemPrefetchAsync(AColIndx, AColIndx_size, device) );\n",
        "\n",
        "    cputimer_stop(\"Prefetching GPU memory to the device\");\n",
        "  }\n",
        "#endif\n",
        "\n",
        "  //@@ Insert code to create the cuBLAS handle\n",
        "  cublasCheck( cublasCreate(&cublasHandle) );\n",
        "  //@@ Insert code to create the cuSPARSE handle\n",
        "  cusparseCheck( cusparseCreate(&cusparseHandle) );\n",
        "\n",
        "  //@@ Insert code to set the cuBLAS pointer mode to CUSPARSE_POINTER_MODE_HOST\n",
        "  cublasSetPointerMode(cublasHandle, CUBLAS_POINTER_MODE_HOST);\n",
        "  // create the Sparse Mat and Dense Vec  descriptor used by cuSPARSE\n",
        "  cusparseCreateCsr(&Adescriptor, dimX, dimX, nzv, ARowPtr, AColIndx, A, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I, CUSPARSE_INDEX_BASE_ZERO, CUDA_R_64F);\n",
        "  cusparseCreateDnVec(&tmpDescriptor, dimX, tmp, CUDA_R_64F);\n",
        "  cusparseCreateDnVec(&tempDescriptor, dimX, temp, CUDA_R_64F);\n",
        "  \n",
        "\n",
        "  //@@ Insert code to call cusparse api to get the buffer size needed by the sparse matrix per\n",
        "  cusparseCheck( cusparseSpMV_bufferSize(cusparseHandle,\n",
        "                                        CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
        "                                        &one,\n",
        "                                        Adescriptor,\n",
        "                                        tempDescriptor,\n",
        "                                        &zero,\n",
        "                                        tmpDescriptor,\n",
        "                                        CUDA_R_64F,\n",
        "                                        CUSPARSE_SPMV_ALG_DEFAULT,\n",
        "                                        &bufferSize)\n",
        "              );\n",
        "  //@@ vector (SMPV) CSR routine of cuSPARSE\n",
        "\n",
        "\n",
        "  //@@ Insert code to allocate the buffer needed by cuSPARSE\n",
        "  gpuCheck( cudaMalloc(&buffer, bufferSize) );\n",
        "\n",
        "  // Perform the time step iterations\n",
        "  for (int it = 0; it < nsteps; ++it) {\n",
        "    //@@ Insert code to call cusparse api to compute the SMPV (sparse matrix multiplication) for\n",
        "    //@@ the CSR matrix using cuSPARSE. This calculation corresponds to:\n",
        "    //@@ tmp = 1 * A * temp + 0 * tmp\n",
        "  cusparseCheck( cusparseSpMV(cusparseHandle,\n",
        "                            CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
        "                            &one,\n",
        "                            Adescriptor,\n",
        "                            tempDescriptor,\n",
        "                            &zero,\n",
        "                            tmpDescriptor,\n",
        "                            CUDA_R_64F,\n",
        "                            CUSPARSE_SPMV_ALG_DEFAULT,\n",
        "                            buffer)\n",
        "            );\n",
        "\n",
        "\n",
        "    //@@ Insert code to call cublas api to compute the axpy routine using cuBLAS.\n",
        "    //@@ This calculation corresponds to: temp = alpha * tmp + temp\n",
        "    cublasCheck( cublasDaxpy(cublasHandle, dimX, &alpha, tmp, 1, temp, 1) );\n",
        "    //@@ Insert code to call cublas api to compute the norm of the vector using cuBLAS\n",
        "    //@@ This calculation corresponds to: ||temp||\n",
        "    cublasCheck( cublasDnrm2(cublasHandle, dimX, tmp, 1, &norm) );\n",
        "    \n",
        "    // If the norm of A*temp is smaller than 10^-4 exit the loop\n",
        "    if (norm < 1e-4)\n",
        "      break;\n",
        "  }\n",
        "\n",
        "  // Calculate the exact solution using thrust\n",
        "  thrust::device_ptr<double> thrustPtr(tmp);\n",
        "  thrust::sequence(thrustPtr, thrustPtr + dimX, tempLeft,\n",
        "      (tempRight - tempLeft) / (dimX - 1));\n",
        "\n",
        "  // Calculate the relative approximation error:\n",
        "  one = -1;\n",
        "  //@@ Insert the code to call cublas api to compute the difference between the exact solution\n",
        "  //@@ and the approximation\n",
        "  //@@ This calculation corresponds to: tmp = -temp + tmp\n",
        "    cublasCheck( cublasDaxpy(cublasHandle,dimX, &one, temp, 1, tmp, 1) );\n",
        "  //@@ Insert the code to call cublas api to compute the norm of the absolute error\n",
        "  //@@ This calculation corresponds to: || tmp ||\n",
        "  cublasCheck( cublasDnrm2(cublasHandle,dimX, tmp, 1, &norm) );\n",
        "  error = norm;\n",
        "  //@@ Insert the code to call cublas api to compute the norm of temp\n",
        "  //@@ This calculation corresponds to: || temp ||\n",
        "  cublasCheck( cublasDnrm2(cublasHandle,dimX, temp, 1, &norm) );\n",
        "  // Calculate the relative error\n",
        "  error = error / norm;\n",
        "  printf(\"The relative error of the approximation is %f\\n\", error);\n",
        "  printf(\"NZM %d\\n\", nzv);\n",
        "\n",
        "  //writing the data to a file \n",
        "  //FILE *filePointer;\n",
        "  //filePointer = fopen(\"data.txt\", \"a\");\n",
        "\n",
        "  //fprintf(filePointer, \"%i\\t\", nsteps);\n",
        "  //fprintf(filePointer, \"%f\\n\", error);\n",
        "\n",
        "  //fclose(filePointer);\n",
        "\n",
        "  //@@ Insert the code to destroy the mat descriptor\n",
        "  cusparseCheck( cusparseDestroySpMat(Adescriptor) );\n",
        "  cusparseCheck( cusparseDestroyDnVec(tmpDescriptor) );\n",
        "  cusparseCheck( cusparseDestroyDnVec(tempDescriptor) );\n",
        "  //@@ Insert the code to destroy the cuSPARSE handle\n",
        "  cusparseCheck( cusparseDestroy(cusparseHandle) );\n",
        "  //@@ Insert the code to destroy the cuBLAS handle\n",
        "  cublasCheck( cublasDestroy(cublasHandle) );\n",
        "\n",
        "\n",
        "  //@@ Insert the code for deallocating memory\n",
        "  cudaFree(temp);\n",
        "  cudaFree(tmp);\n",
        "  cudaFree(A);\n",
        "  cudaFree(ARowPtr);\n",
        "  cudaFree(AColIndx);\n",
        "  cudaFree(buffer);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkM3sD6NsCz8",
        "outputId": "4202ce49-3583-4fd5-d3e6-99d9b80e022d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting heatEq.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc heatEq.cu -O3 -o heatEq -lm -lcublas -lcusparse "
      ],
      "metadata": {
        "id": "GZGpKu2BsT4Z"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell \n",
        "#!/bin/bash\n",
        "\n",
        "for nstep in $(seq 100 100 10000); do\n",
        "    echo \"Running with nstep = $nstep\"\n",
        "    ./heatEq 128 $nstep\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13KsjB7Fsyg0",
        "outputId": "1197a6d5-64c3-434c-8de1-db5e84ebb14c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with nstep = 100\n",
            "Running with nstep = 200\n",
            "Running with nstep = 300\n",
            "Running with nstep = 400\n",
            "Running with nstep = 500\n",
            "Running with nstep = 600\n",
            "Running with nstep = 700\n",
            "Running with nstep = 800\n",
            "Running with nstep = 900\n",
            "Running with nstep = 1000\n",
            "Running with nstep = 1100\n",
            "Running with nstep = 1200\n",
            "Running with nstep = 1300\n",
            "Running with nstep = 1400\n",
            "Running with nstep = 1500\n",
            "Running with nstep = 1600\n",
            "Running with nstep = 1700\n",
            "Running with nstep = 1800\n",
            "Running with nstep = 1900\n",
            "Running with nstep = 2000\n",
            "Running with nstep = 2100\n",
            "Running with nstep = 2200\n",
            "Running with nstep = 2300\n",
            "Running with nstep = 2400\n",
            "Running with nstep = 2500\n",
            "Running with nstep = 2600\n",
            "Running with nstep = 2700\n",
            "Running with nstep = 2800\n",
            "Running with nstep = 2900\n",
            "Running with nstep = 3000\n",
            "Running with nstep = 3100\n",
            "Running with nstep = 3200\n",
            "Running with nstep = 3300\n",
            "Running with nstep = 3400\n",
            "Running with nstep = 3500\n",
            "Running with nstep = 3600\n",
            "Running with nstep = 3700\n",
            "Running with nstep = 3800\n",
            "Running with nstep = 3900\n",
            "Running with nstep = 4000\n",
            "Running with nstep = 4100\n",
            "Running with nstep = 4200\n",
            "Running with nstep = 4300\n",
            "Running with nstep = 4400\n",
            "Running with nstep = 4500\n",
            "Running with nstep = 4600\n",
            "Running with nstep = 4700\n",
            "Running with nstep = 4800\n",
            "Running with nstep = 4900\n",
            "Running with nstep = 5000\n",
            "Running with nstep = 5100\n",
            "Running with nstep = 5200\n",
            "Running with nstep = 5300\n",
            "Running with nstep = 5400\n",
            "Running with nstep = 5500\n",
            "Running with nstep = 5600\n",
            "Running with nstep = 5700\n",
            "Running with nstep = 5800\n",
            "Running with nstep = 5900\n",
            "Running with nstep = 6000\n",
            "Running with nstep = 6100\n",
            "Running with nstep = 6200\n",
            "Running with nstep = 6300\n",
            "Running with nstep = 6400\n",
            "Running with nstep = 6500\n",
            "Running with nstep = 6600\n",
            "Running with nstep = 6700\n",
            "Running with nstep = 6800\n",
            "Running with nstep = 6900\n",
            "Running with nstep = 7000\n",
            "Running with nstep = 7100\n",
            "Running with nstep = 7200\n",
            "Running with nstep = 7300\n",
            "Running with nstep = 7400\n",
            "Running with nstep = 7500\n",
            "Running with nstep = 7600\n",
            "Running with nstep = 7700\n",
            "Running with nstep = 7800\n",
            "Running with nstep = 7900\n",
            "Running with nstep = 8000\n",
            "Running with nstep = 8100\n",
            "Running with nstep = 8200\n",
            "Running with nstep = 8300\n",
            "Running with nstep = 8400\n",
            "Running with nstep = 8500\n",
            "Running with nstep = 8600\n",
            "Running with nstep = 8700\n",
            "Running with nstep = 8800\n",
            "Running with nstep = 8900\n",
            "Running with nstep = 9000\n",
            "Running with nstep = 9100\n",
            "Running with nstep = 9200\n",
            "Running with nstep = 9300\n",
            "Running with nstep = 9400\n",
            "Running with nstep = 9500\n",
            "Running with nstep = 9600\n",
            "Running with nstep = 9700\n",
            "Running with nstep = 9800\n",
            "Running with nstep = 9900\n",
            "Running with nstep = 10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./heatEq 128 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbudbUviUftG",
        "outputId": "7562086c-fd54-45a8-f135-c8484dea2009"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The X dimension of the grid is 128 \n",
            "The number of time steps to perform is 100 \n",
            "==22298== NVPROF is profiling process 22298, command: ./heatEq 128 100\n",
            "Timing - Allocating device memory. \t\tElasped 421734 microseconds \n",
            "Timing - Prefetching GPU memory to the host. \t\tElasped 99 microseconds \n",
            "Timing - Initializing the sparse matrix on the host. \t\tElasped 2 microseconds \n",
            "Timing - Initializing memory on the host. \t\tElasped 0 microseconds \n",
            "Timing - Prefetching GPU memory to the device. \t\tElasped 351 microseconds \n",
            "The relative error of the approximation is 3.318021\n",
            "NZM 378\n",
            "==22298== Profiling application: ./heatEq 128 100\n",
            "==22298== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   75.79%  9.7129ms       204  47.612us  43.807us  52.767us  void nrm2_kernel<double, double, double, int=0, int=0, int=128>(cublasNrm2Params<double, double>)\n",
            "                   12.58%  1.6127ms       100  16.127us  16.032us  16.864us  _ZN8cusparse21load_balancing_kernelILj512ELj4ELm16384EiiNS_7CsrmvOpILi512EdLb0EEEJKiKdS4_didEEEvPKT3_T2_S5_S5_iPKS8_T4_DpPT5_\n",
            "                    5.35%  686.03us       100  6.8600us  6.7830us  9.1190us  _ZN8cusparse30binary_search_partition_kernelILi128ELi2048EiiNS_6ScaleYINS_20MatrixWiseMulPolicy1ILb0EdEEidEEJdEEEvPKT2_T1_S5_iPS8_T3_DpPT4_\n",
            "                    3.82%  488.99us       101  4.8410us  4.7040us  6.5920us  void axpy_kernel_val<double, double>(cublasAxpyParamsVal<double, double, double>)\n",
            "                    1.28%  164.00us       102  1.6070us  1.5670us  2.0480us  [CUDA memcpy DtoH]\n",
            "                    1.15%  146.85us       102  1.4390us  1.4070us  1.8880us  [CUDA memcpy HtoD]\n",
            "                    0.03%  4.4160us         1  4.4160us  4.4160us  4.4160us  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__tabulate::functor<thrust::device_ptr<double>, thrust::detail::functional::actor<thrust::detail::functional::composite<thrust::detail::functional::transparent_binary_operator<thrust::plus<void>>, thrust::detail::functional::value<double>, thrust::detail::functional::actor<thrust::detail::functional::composite<thrust::detail::functional::transparent_binary_operator<thrust::multiplies<void>>, thrust::detail::functional::value<double>, thrust::detail::functional::actor<thrust::detail::functional::argument<unsigned int=0>>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>, long>, long>, thrust::cuda_cub::__tabulate::functor<thrust::device_ptr<double>, thrust::detail::functional::actor<thrust::detail::functional::composite<thrust::detail::functional::transparent_binary_operator<thrust::plus<void>>, thrust::detail::functional::value<double>, thrust::detail::functional::actor<thrust::detail::functional::composite<thrust::detail::functional::transparent_binary_operator<thrust::multiplies<void>>, thrust::detail::functional::value<double>, thrust::detail::functional::actor<thrust::detail::functional::argument<unsigned int=0>>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>, long>, long>(thrust::device_ptr<double>, void)\n",
            "      API calls:   70.45%  1.05035s        12  87.529ms  3.7450us  454.59ms  cudaFree\n",
            "                   28.28%  421.68ms         5  84.336ms  4.3360us  421.64ms  cudaMallocManaged\n",
            "                    0.82%  12.160ms       204  59.607us  2.9710us  128.11us  cudaMemcpyAsync\n",
            "                    0.16%  2.3701ms       506  4.6840us  3.3450us  33.075us  cudaLaunchKernel\n",
            "                    0.11%  1.6619ms         4  415.47us  345.06us  584.10us  cuDeviceTotalMem\n",
            "                    0.05%  691.81us       395  1.7510us     126ns  112.78us  cuDeviceGetAttribute\n",
            "                    0.03%  435.91us        10  43.590us  2.4930us  208.68us  cudaMemPrefetchAsync\n",
            "                    0.02%  283.01us         4  70.752us  4.6100us  162.11us  cudaMalloc\n",
            "                    0.02%  226.83us       103  2.2020us  1.9900us  4.4920us  cudaFuncGetAttributes\n",
            "                    0.01%  190.77us       103  1.8520us  1.5480us  6.1340us  cudaStreamSynchronize\n",
            "                    0.01%  164.27us         1  164.27us  164.27us  164.27us  cudaGetDeviceProperties\n",
            "                    0.01%  155.63us       102  1.5250us  1.3660us  3.9600us  cudaEventQuery\n",
            "                    0.01%  141.25us       306     461ns     306ns  12.499us  cudaStreamGetCaptureInfo\n",
            "                    0.01%  130.51us       621     210ns     124ns  1.1700us  cudaGetLastError\n",
            "                    0.01%  121.00us         4  30.249us  19.084us  35.527us  cuDeviceGetName\n",
            "                    0.01%  80.186us       102     786ns     669ns  2.3600us  cudaEventRecord\n",
            "                    0.00%  24.261us        18  1.3470us     380ns  8.3830us  cudaEventCreateWithFlags\n",
            "                    0.00%  12.844us         8  1.6050us     306ns  4.1290us  cudaGetDevice\n",
            "                    0.00%  11.161us         4  2.7900us     942ns  5.0200us  cudaDeviceSynchronize\n",
            "                    0.00%  10.746us        18     597ns     326ns  1.8390us  cudaEventDestroy\n",
            "                    0.00%  8.5450us        14     610ns     291ns  2.3800us  cudaDeviceGetAttribute\n",
            "                    0.00%  7.6670us         3  2.5550us  2.3220us  2.7140us  cuInit\n",
            "                    0.00%  5.5650us         1  5.5650us  5.5650us  5.5650us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.3780us         6     563ns     214ns  1.4410us  cuDeviceGetCount\n",
            "                    0.00%  2.4790us         5     495ns     276ns  1.0970us  cuDeviceGet\n",
            "                    0.00%  1.6100us         3     536ns     273ns     930ns  cuDriverGetVersion\n",
            "                    0.00%  1.0370us         1  1.0370us  1.0370us  1.0370us  cudaGetSymbolAddress\n",
            "                    0.00%  1.0350us         4     258ns     212ns     293ns  cuDeviceGetUuid\n",
            "                    0.00%     389ns         2     194ns     141ns     248ns  cudaPeekAtLastError\n",
            "                    0.00%     272ns         1     272ns     272ns     272ns  cudaGetDeviceCount\n",
            "\n",
            "==22298== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB  5.696000us  Host To Device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the text file into a pandas DataFrame\n",
        "data = pd.read_csv(\"data.txt\", sep=\"\\t\", header=None, names=[\"x\", \"y\"])\n",
        "\n",
        "# Plot the data using matplotlib\n",
        "plt.plot(data[\"x\"], data[\"y\"])\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "wKSJM103YJlY",
        "outputId": "e85d2d69-e656-4927-f3e4-a79e7af5db97"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}